---
-
  include: tests/templates/rebalance.yml, tests/templates/vegeta.yml, tests/templates/kv.yml, tests/templates/fts.yml, tests/templates/n1ql.yml, tests/templates/multinode_failure.yml, tests/templates/collections.yml

###### update Tombstone Purge Interval ######
-
  image: sequoiatools/couchbase-cli
  requires:  "{{eq true .DoOnce }}"
  command: "setting-compaction -c {{.Orchestrator}} -u  {{.RestUsername}} -p  {{.RestPassword}} --metadata-purge-interval .04 --compaction-db-percentage 30 --compaction-view-percentage 30"
  wait: true

###### Create scopes and collections in local cluster ######
- template: create-scopes
  args: "{{.Orchestrator}}, {{.NthBucket 4}}, 7"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Orchestrator}}, {{.NthBucket 5}}, 6"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Orchestrator}}, {{.NthBucket 6}}, 6"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Orchestrator}}, {{.NthBucket 7}}, 6"
  requires:  "{{eq true .DoOnce }}"
## Create 10 scopes across 2 buckets as scope-1, scope-2. The Collection CRUD workload will be run against these buckets.
- args: "{{.Orchestrator}}, {{.NthBucket 8}}, 5"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 5"
  requires:  "{{eq true .DoOnce }}"

- template: create-collections
  args: "{{.Orchestrator}}, {{.NthBucket 4}}, 6, 8"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Orchestrator}}, {{.NthBucket 5}}, 5, 8"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Orchestrator}}, {{.NthBucket 6}}, 5, 8"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Orchestrator}}, {{.NthBucket 7}}, 5, 8"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
  requires:  "{{eq true .DoOnce }}"

###### Create scopes and collections in remote cluster  ######
- template: create-scopes
  args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 4}}, 7"
  requires:  "{{eq true .DoOnce }}"
## Create 10 scopes across 2 buckets as scope-1, scope-2. The Collection CRUD workload will be run against these buckets.
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 5"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 5"
  requires:  "{{eq true .DoOnce }}"

- template: create-collections
  args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 4}}, 6, 8"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
  requires:  "{{eq true .DoOnce }}"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"
  requires:  "{{eq true .DoOnce }}"

# Sleep for some time to allow collections manifest to sync
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "300"
   wait: true

# continous kv loading
- template: pillowfight_durability
  args: "{{.Orchestrator}}, {{.Bucket}}, -M 512 -I {{.Scale 2000}} -B {{.Scale 200}} -t 1  --rate-limit {{.Scale 2000}}, {{.AuthPassword}} --durability majority"

#### Load pillowfight data to bucket8 & 9 ####
-
  foreach: "{{range $i, $sc := mkrange 0 4}}"
  image: sequoiatools/pillowfight:7.0
  command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 8}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
- command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 9}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
  
# Sleep for some time to allow some docs to be loaded to the collections
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true

### delete all collections in scope #### --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: delete-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

# rebalance out a node
- template: rebalance_out
  args: "{{.ActiveDataNode 1}}:{{.RestPort}}"
  wait: true

### recreate the dropped collections
- template: create-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

#### Load pillowfight data to bucket8 & 9 ####
-
  foreach: "{{range $i, $sc := mkrange 0 4}}"
  image: sequoiatools/pillowfight:7.0
  command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 8}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
- command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 9}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"

# Sleep for some time to allow some docs to be loaded to the collections
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true

# creating eventing handlers and deploying them
- test: tests/eventing/test_eventing_rebalance_integration_timers.yml
  section: create_and_deploy

# creating datasets and indexes
- test: tests/analytics/test_analytics_integration.yml
  section: analytics_setup

# GSI Index Creation
# Create index on the default bucket so that the query workloads below in the test have indexes to work with
- image: sequoiatools/cbq
  command: "-e=http://{{.QueryNodePort}}  -u={{.RestUsername}} -p={{.RestPassword}} -script='create index default_rating on `{{.Bucket}}`(rating) using GSI'"
  wait: true
- command: "-e=http://{{.QueryNodePort}}  -u={{.RestUsername}} -p={{.RestPassword}} -script='create index default_claims on `{{.Bucket}}`(claim) using GSI'"
  wait: true
- command: "-e=http://{{.QueryNodePort}}  -u={{.RestUsername}} -p={{.RestPassword}} -script='create index default_result on `{{.Bucket}}`(result) using GSI'"
- command: "-e=http://{{.QueryNodePort}}  -u={{.RestUsername}} -p={{.RestPassword}} -script='create primary index on `{{.Bucket}}` using GSI'"
  wait: true

# Create indexes on the collections
- image: sequoiatools/indexmanager
  command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 4}} -i 5 -a create_index"
  wait: true

- command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 5}} -i 5 -a create_index"
  wait: true

- command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 6}} -i 5 -a create_index"
  wait: true

- command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 7}} -i 5 -a create_index"
  wait: true

###############  build all deferred indexes ################

- image: sequoiatools/indexmanager
  command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 4}} -a build_deferred_index"
  wait: true

- command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 5}} -a build_deferred_index"
  wait: true

- command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 6}} -a build_deferred_index"
  wait: true

- command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 7}} -a build_deferred_index"
  wait: true


# Wait till all indexes are completely built
-
   image: sequoiatools/wait_for_idx_build_complete
   command: "{{.ActiveIndexNode 0}} {{.RestUsername}} {{.RestPassword}}"
   wait: true

# replica data loading for 30 minutes with docs that will expire after 1 hour
- image: sequoiatools/gideon
  command: "kv --ops {{.Scale 500}} --create 10 --delete 8 --get 82 --sizes 64 96  --expire 100 --ttl 3600  --hosts {{.Orchestrator}} --bucket {{.NthBucket 1}}"
  duration: 1800
- command: "kv --ops {{.Scale 500}} --create 10 --delete 8 --get 82 --sizes 64 96  --expire 100 --ttl 3600  --hosts {{.Orchestrator}} --bucket {{.NthBucket 2}}"
  duration: 1800
- command: "kv --ops {{.Scale 500}} --create 10 --delete 8 --get 82 --sizes 64 96  --expire 100 --ttl 3600  --hosts {{.Orchestrator}} --bucket {{.NthBucket 3}}"
  duration: 1800

############### data loading to collections ################
- image: sequoiatools/catapult
  command: "-i {{.Orchestrator}} -u Administrator -p password -b {{.NthBucket 4}} -n {{.Scale 40000}} -pc 100 -pu 25 -pd 25 -dt Hotel -de {{.Scale 7200}} -ds 1000 -lf
    -fu \"\" -ac True"
- command: "-i {{.Orchestrator}} -u Administrator -p password -b {{.NthBucket 5}} -n {{.Scale 40000}} -pc 100 -pu 25 -pd 25 -dt Hotel -de {{.Scale 7200}} -ds 1000 -lf
    -fu \"\" -ac True"
- command: "-i {{.Orchestrator}} -u Administrator -p password -b {{.NthBucket 6}} -n {{.Scale 40000}} -pc 100 -pu 25 -pd 25 -dt Hotel -de {{.Scale 7200}} -ds 1000 -lf
    -fu \"\" -ac True"
- command: "-i {{.Orchestrator}} -u Administrator -p password -b {{.NthBucket 7}} -n {{.Scale 40000}} -pc 100 -pu 25 -pd 25 -dt Hotel -de {{.Scale 7200}} -ds 1000 -lf
    -fu \"\" -ac True"


# query replica indexes
- image: sequoiatools/queryapp
  command: "-J-cp /AnalyticsQueryApp/Couchbase-Java-Client-2.5.6/* /AnalyticsQueryApp/Query/load_queries.py --server_ip {{.Nodes | .Service `n1ql` | net 0}} --port {{.QueryPort}} --duration {{.Scale 3600}} --print_duration=3600 --bucket {{.NthBucket 4}} --querycount 10 --threads 10 --n1ql True --query_timeout=600 --scan_consistency REQUEST_PLUS --bucket_names [{{.NthBucket 4}},{{.NthBucket 5}},{{.NthBucket 6}},{{.NthBucket 7}}] --collections_mode --dataset hotel"
- command: "-J-cp /AnalyticsQueryApp/Couchbase-Java-Client-2.5.6/* /AnalyticsQueryApp/Query/load_queries.py --server_ip {{.Nodes | .Service `n1ql` | net 0}} --port {{.QueryPort}} --duration {{.Scale 3600}} --print_duration=3600 --bucket {{.NthBucket 5}} --querycount 10 --threads 10 --n1ql True --query_timeout=600 --scan_consistency REQUEST_PLUS --bucket_names [{{.NthBucket 4}},{{.NthBucket 5}},{{.NthBucket 6}},{{.NthBucket 7}}] --collections_mode --dataset hotel"
- command: "-J-cp /AnalyticsQueryApp/Couchbase-Java-Client-2.5.6/* /AnalyticsQueryApp/Query/load_queries.py --server_ip {{.Nodes | .Service `n1ql` | net 0}} --port {{.QueryPort}} --duration {{.Scale 3600}} --print_duration=3600 --bucket {{.NthBucket 6}} --querycount 10 --threads 10 --n1ql True --query_timeout=600 --scan_consistency REQUEST_PLUS --bucket_names [{{.NthBucket 4}},{{.NthBucket 5}},{{.NthBucket 6}},{{.NthBucket 7}}] --collections_mode --dataset hotel"
- command: "-J-cp /AnalyticsQueryApp/Couchbase-Java-Client-2.5.6/* /AnalyticsQueryApp/Query/load_queries.py --server_ip {{.Nodes | .Service `n1ql` | net 0}} --port {{.QueryPort}} --duration {{.Scale 3600}} --print_duration=3600 --bucket {{.NthBucket 7}} --querycount 10 --threads 10 --n1ql True --query_timeout=600 --scan_consistency REQUEST_PLUS --bucket_names [{{.NthBucket 4}},{{.NthBucket 5}},{{.NthBucket 6}},{{.NthBucket 7}}] --collections_mode --dataset hotel"
  wait: true

### delete all collections in scope ####
- template: delete-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

# swap rebalance
- template: rebalance_swap
  args: "{{.InActiveNode}}, {{.ActiveDataNode 2}}"
  wait: true

### recreate the dropped collections
- template: create-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

#### Load pillowfight data to bucket8 & 9 ####
-
  foreach: "{{range $i, $sc := mkrange 0 4}}"
  image: sequoiatools/pillowfight:7.0
  command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 8}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
- command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 9}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"

# Sleep for some time to allow some docs to be loaded to the collections
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true

# run queries and then connect to bucket
- test: tests/analytics/test_analytics_integration.yml
  section: analytics_query

# run http attacks against n1ql with various skip param
- template: attack_query
  args: "0, 10, {{$.NthQueryNode 1}}:{{$.QueryPort}},
        delete from default where rating > 0 limit {{$.Scale 10}}"

# more json docs on default bucket
- image: sequoiatools/gideon
  command: "kv --ops {{.Scale 500}} --create 10 --delete 8 --get 92 --expire 100 --ttl 660  --hosts {{.Orchestrator}} --bucket {{.Bucket}} --sizes  512 128 1024 2048 16000"
- command: "kv --ops {{.Scale 500}} --create 100  --expire 100 --ttl 660 --hosts {{.Orchestrator}} --bucket {{.Bucket}} --sizes 64"
  duration: 600
- command: "kv --ops {{.Scale 600}} --create 15 --get 80 --delete 5  --expire 100 --ttl 660 --hosts {{.Orchestrator}} --bucket {{.Bucket}} --sizes 128"
  duration: 7200

### delete all collections in scope ####
- template: delete-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

# Change the topology (performs rebalance in/out/swap eventing nodes)
- test: tests/eventing/test_eventing_rebalance_integration_timers.yml
  section: topology_change

### recreate the dropped collections
- template: create-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

#### Load pillowfight data to bucket8 & 9 ####
-
  foreach: "{{range $i, $sc := mkrange 0 4}}"
  image: sequoiatools/pillowfight:7.0
  command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 8}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
- command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 9}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"


# Sleep for some time to allow some docs to be loaded to the collections
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true

### delete all collections in scope #### --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: delete-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

# Change the topology (performs rebalance in/out/swap analytics nodes)
- test: tests/analytics/test_analytics_integration.yml
  section: analytics_topology_change

### recreate the dropped collections  --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: create-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

#### Load pillowfight data to bucket8 & 9 ####
-
  foreach: "{{range $i, $sc := mkrange 0 4}}"
  image: sequoiatools/pillowfight:7.0
  command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 8}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
- command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 9}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"

# Sleep for some time to allow some docs to be loaded to the collections
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true

# run http attacks against view with various skip param
- foreach: "{{range $i, $view := strlist `stats` `array` `padd`}}"
  template: attack_view
  args: "0, 10, {{$.NthDataNode $i}},
         {{$.Bucket}},
         scale,
         {{$view}},
         limit={{$.Scale 10}}&stale=update_after&connection_timeout=60000"

# create fts index with custom child field using result key as type
- template: create_index_with_child_field
  args: "{{.FTSNodePort}}, good_state, default, SUCCESS, state, false, result, scorch"
  wait: true

# create fts index with nested type mappings and store results
- template: create_index_with_child_field_nested_type_mapping
  args: "{{.FTSNodePort}}, social, default, gideon, description, profile, status, true, , scorch"

# direct search on state key
- template: query_fts
  args: "{{.FTSNodePort}}, -1, {{.Scale 3}}, good_state, +state:9C, -size 10"


# regex search on subfield profile.status with description exclusion
- template: query_fts
  args: "{{.FTSNodePort}}, -1, {{.Scale 3}}, social, +profile.status:4121*, -size 10"


# start xdcr replications
- image: sequoiatools/couchbase-cli
  requires:  "{{eq true .DoOnce }}"
  command:  "xdcr-setup -c {{.Orchestrator}}:{{.RestPort}} --create --xdcr-cluster-name remote
        --xdcr-hostname {{.Nodes | .Cluster 1 | net 0}}
        --xdcr-username {{.Nodes | .Cluster 1 | .Attr `rest_username`}}
        --xdcr-password {{.Nodes | .Cluster 1 | .Attr `rest_password`}}"
  wait: true
- command: "xdcr-replicate -c {{.Orchestrator}}:{{.RestPort}}
        --create
        --xdcr-cluster-name remote
        --xdcr-from-bucket {{.Bucket}}
        --xdcr-to-bucket {{.Nodes | .Cluster 1 | bucket 0}}
	--enable-compression 1"
  wait: true
- command: "xdcr-replicate -c {{.Orchestrator}}:{{.RestPort}}
        --create
        --xdcr-cluster-name remote
        --xdcr-from-bucket {{.NthBucket 4}}
        --xdcr-to-bucket {{.Nodes | .Cluster 1 | bucket 1}}
        --enable-compression 1"
  wait: true
- command: "xdcr-replicate -c {{.Orchestrator}}:{{.RestPort}}
        --create
        --xdcr-cluster-name remote
        --xdcr-from-bucket {{.NthBucket 8}}
        --xdcr-to-bucket {{.Nodes | .Cluster 1 | bucket 2}}
        --enable-compression 1"
  wait: true
- command: "xdcr-replicate -c {{.Orchestrator}}:{{.RestPort}}
        --create
        --xdcr-cluster-name remote
        --xdcr-from-bucket {{.NthBucket 9}}
        --xdcr-to-bucket {{.Nodes | .Cluster 1 | bucket 3}}
        --enable-compression 1"
  wait: true

# get replication id
-
  image:  appropriate/curl
  command: "-s http://{{.RestUsername}}:{{.RestPassword}}@{{.Orchestrator | noport}}:{{.ClusterNodes | .Attr `rest_port`}}/pools/default/remoteClusters"
  alias: ReplId
  wait: true

# apply adv filtering to xdcr replications
- image: appropriate/curl
  requires:  "{{eq true .DoOnce }}"
  command: "-u {{.RestUsername}}:{{.RestPassword}} -X POST http://{{.Orchestrator}}:{{.RestPort}}/settings/replications/{{(index (.AllLogs `ReplId` | json) 0).uuid }}/default/{{.Bucket}} -d filterExpression=rating>500 -d filterSkipRestream=0"
  wait: true
- command: "-u {{.RestUsername}}:{{.RestPassword}} -X POST http://{{.Orchestrator}}:{{.RestPort}}/settings/replications/{{(index (.AllLogs `ReplId` | json) 0).uuid }}/default/{{.Bucket}} -d filterExpression=REGEXP_CONTAINS(META().id,0$) -d filterSkipRestream=0"
  wait: true
- command: "-u {{.RestUsername}}:{{.RestPassword}} -X POST http://{{.Orchestrator}}:{{.RestPort}}/settings/replications/{{(index (.AllLogs `ReplId` | json) 0).uuid }}/default/{{.Bucket}} -d filterExpiration=true -d filterBypassExpiry=true -d filterDeletion=false -d filterExpression=result<>SUCCESS -d filterSkipRestream=1"
  wait: true

# add some rbac users
- test: tests/n1ql/test_n1qlRBAC.yml
  section: add_users

# start rbac queries
- test: tests/n1ql/test_n1qlRBAC.yml
  section: rbac_query

# pause eventing handlers
- test: tests/eventing/test_eventing_rebalance_integration_timers.yml
  section: pause

# load 1M items
- template: pillowfight_htp
  wait: true

### delete all collections in scope #### --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: delete-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

# change the topologies on the 2i test
- test: tests/2i/test_idx_mad_hatter_integration.yml
  section: change_indexer_topologies

### recreate the dropped collections  --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: create-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

#### Load pillowfight data to bucket8 & 9 ####
-
  foreach: "{{range $i, $sc := mkrange 0 4}}"
  image: sequoiatools/pillowfight:7.0
  command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 8}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
- command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 9}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"

# Sleep for some time to allow some docs to be loaded to the collections
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true

# resume eventing handlers
- test: tests/eventing/test_eventing_rebalance_integration_timers.yml
  section: resume

# quick update batch
- template: pillowfight_htp
  wait: true

### delete all collections in scope #### --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: delete-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

# swap failover
- template: add_node
  args: "{{.InActiveNode}}"
- template: failover_node_forced
  args: "{{.ActiveDataNode 1}}"
- template: rebalance
  wait: true

### recreate the dropped collections  --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: create-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

#### Load pillowfight data to bucket8 & 9 ####
-
  foreach: "{{range $i, $sc := mkrange 0 4}}"
  image: sequoiatools/pillowfight:7.0
  command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 8}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
- command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 9}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"

# Sleep for some time to allow some docs to be loaded to the collections
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true

# load some new docs
- image: sequoiatools/gideon
  command: "kv --ops {{.Scale 500}} --create 100  --expire 100 --ttl 660 --hosts {{.Orchestrator}} --bucket {{.Bucket}} --sizes 64"
  duration: 1800

# quick update batch
- template: pillowfight_htp
  wait: true

### delete all collections in scope #### --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: delete-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

# swap hard failover
- template: add_node
  args: "{{.InActiveNode}}"
- template: failover_node
  args: "{{.ActiveDataNode 2}}"
- template: failover_node_forced
  args: "{{.ActiveDataNode 3}}"
- template: rebalance
  wait: true

### recreate the dropped collections  --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: create-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

#### Load pillowfight data to bucket8 & 9 ####
-
  foreach: "{{range $i, $sc := mkrange 0 4}}"
  image: sequoiatools/pillowfight:7.0
  command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 8}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
- command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 9}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"

# Sleep for some time to allow some docs to be loaded to the collections
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true

### delete all collections in scope #### --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: delete-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

# do multinode failover , failing only one node as we have 1 replica
- template: autofailover1Node
  args: "{{.ActiveDataNode 1}}"
  wait: true

### recreate the dropped collections  --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: create-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

#### Load pillowfight data to bucket8 & 9 ####
-
  foreach: "{{range $i, $sc := mkrange 0 4}}"
  image: sequoiatools/pillowfight:7.0
  command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 8}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
- command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 9}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"

# Sleep for some time to allow some docs to be loaded to the collections
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true
# quick update batch
- template: pillowfight_htp
  wait: true

### delete all collections in scope #### --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: delete-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

- template: add_node
  args: "{{.NthInActiveNode 0}}"
- args: "{{.NthInActiveNode 1}}"
- template: rebalance
  wait: true

### recreate the dropped collections  --> Replace this with the Collection CRUD workload that will run throughout the test in the background
- template: create-collections
  args: "{{.Orchestrator}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Orchestrator}}, {{.NthBucket 9}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 8}}, 4, 5"
- args: "{{.Nodes | .Cluster 1 | net 0}}, {{.NthBucket 9}}, 4, 5"

#### Load pillowfight data to bucket8 & 9 ####
-
  foreach: "{{range $i, $sc := mkrange 0 4}}"
  image: sequoiatools/pillowfight:7.0
  command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 8}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"
- command: "-u Administrator -P password -U couchbase://{{$.Orchestrator}}/{{.NthBucket 9}} -I {{$.Scale 1000}} -M 50 -B 100 -r 90 --rate-limit {{$.Scale 500}} --random-body
  --collection scope{{$sc}}.collection1 --collection scope{{$sc}}.collection2 --collection scope{{$sc}}.collection3 --collection scope{{$sc}}.collection4 --collection scope{{$sc}}.collection5
  --json"

# Sleep for some time to allow some docs to be loaded to the collections
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true
   
# undeploy eventing handlers
- test: tests/eventing/test_eventing_rebalance_integration_timers.yml
  section: undeploy

# delete eventing handlers
- test: tests/eventing/test_eventing_rebalance_integration_timers.yml
  section: delete_functions

# analytics drop bucket , datasets and indexes
- test: tests/analytics/test_analytics_integration.yml
  section: analytics_teardown

# Drop GSI indexes
- image: sequoiatools/indexmanager
  command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 4}} -a drop_all_indexes"
  wait: true

- command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 5}} -a drop_all_indexes"
  wait: true

- command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 6}} -a drop_all_indexes"
  wait: true

- command: "-n {{.Orchestrator}} -o {{.RestPort}} -u {{.RestUsername}} -p {{.RestPassword}} -b {{.NthBucket 7}} -a drop_all_indexes"
  wait: true

# Sleep for some time to allow DDL to complete in the background
-
   image: sequoiatools/cmd
   entrypoint: sleep
   command: "600"
   wait: true
